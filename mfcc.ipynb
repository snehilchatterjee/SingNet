{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import librosa\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "\n",
    "from torchvision.models import resnet34\n",
    "\n",
    "device =  'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_random(x: np.ndarray, max_len: int = 64000):\n",
    "    x_len = x.shape[0]\n",
    "    if x_len > max_len:\n",
    "        stt = np.random.randint(x_len - max_len)\n",
    "        return x[stt:stt + max_len]\n",
    "\n",
    "    num_repeats = int(max_len / x_len) + 1\n",
    "    padded_x = np.tile(x, (num_repeats))\n",
    "    return pad_random(padded_x, max_len)\n",
    "\n",
    "class SVDD2024(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for the SVDD 2024 dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_dir, partition=\"train\", max_len=64000):\n",
    "        assert partition in [\"train\", \"dev\", \"test\"], \"Invalid partition. Must be one of ['train', 'dev', 'test']\"\n",
    "        self.base_dir = base_dir\n",
    "        self.partition = partition\n",
    "        self.base_dir = os.path.join(base_dir, partition + \"_set\")\n",
    "        self.max_len = max_len\n",
    "\n",
    "        self.transforms = torchvision.transforms.Compose([torchvision.transforms.Resize((224,224))])\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(base_dir, f\"{partition}.txt\"), \"r\") as f:\n",
    "                self.file_list = f.readlines()\n",
    "        except FileNotFoundError:\n",
    "            if partition == \"test\":\n",
    "                self.file_list = []\n",
    "                # get all *.flac files in the test_set directory\n",
    "                for root, _, files in os.walk(self.base_dir):\n",
    "                    for file in files:\n",
    "                        if file.endswith(\".flac\"):\n",
    "                            self.file_list.append(file)\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"File {partition}.txt not found in {base_dir}\")\n",
    "\n",
    "\n",
    "            \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, index):            \n",
    "        if self.partition == \"test\":\n",
    "            file_name = self.file_list[index].strip()\n",
    "            label = 0 # dummy label. Not used for test set.\n",
    "        else:\n",
    "            file = self.file_list[index]\n",
    "            file_name = file.split(\" \")[2].strip()\n",
    "            bonafide_or_spoof = file.split(\" \")[-1].strip()\n",
    "            label = 1 if bonafide_or_spoof == \"bonafide\" else 0\n",
    "        try:\n",
    "            x, _ = librosa.load(os.path.join(self.base_dir, file_name + \".flac\"), sr=16000, mono=True)\n",
    "            x = pad_random(x, self.max_len) # x = pad_random (audio,64000)\n",
    "            x = librosa.util.normalize(x)\n",
    "            \n",
    "            x = librosa.feature.mfcc(y=x, sr=16000, n_mfcc=44,hop_length=160,win_length=320)\n",
    "            \n",
    "            return torch.unsqueeze(torch.tensor(x),dim=0), label, file_name\n",
    "            \n",
    "            #x = librosa.feature.chroma_cqt(y=x,sr=16000)\n",
    "            #x = np.abs(librosa.stft(x))\n",
    "            #x= librosa.amplitude_to_db(x,ref=np.max)\n",
    "            # file_name is used for generating the score file for submission\n",
    "            #return self.transforms(torch.unsqueeze(torch.from_numpy(x),dim=0)), label, file_name\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_name}: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds=SVDD2024('./temp/ds/',partition='train')\n",
    "test_ds=SVDD2024('./temp/ds/',partition='dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(train_ds,batch_size=16,num_workers=4)\n",
    "test_loader=torch.utils.data.DataLoader(test_ds,batch_size=16,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 44, 401])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im=next(iter(train_loader))[0]\n",
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=resnet34()\n",
    "model.conv1=nn.Conv2d(1,64,kernel_size=(7,7),stride=(2,2),padding=(3,3),bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc=nn.Linear(512,1,bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    out=model(im)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5659, 0.6237, 0.5919, 0.6035, 0.5649, 0.5832, 0.5538, 0.5650, 0.6342,\n",
       "        0.5868, 0.6292, 0.5994, 0.6193, 0.5587, 0.5936, 0.6003])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(out).detach().squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EER Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_det_curve(target_scores, nontarget_scores):\n",
    "\n",
    "    n_scores = target_scores.size + nontarget_scores.size\n",
    "    all_scores = np.concatenate((target_scores, nontarget_scores))\n",
    "    labels = np.concatenate((np.ones(target_scores.size), np.zeros(nontarget_scores.size)))\n",
    "\n",
    "    # Sort labels based on scores\n",
    "    indices = np.argsort(all_scores, kind='mergesort')\n",
    "    labels = labels[indices]\n",
    "\n",
    "    # Compute false rejection and false acceptance rates\n",
    "    tar_trial_sums = np.cumsum(labels)\n",
    "    nontarget_trial_sums = nontarget_scores.size - (np.arange(1, n_scores + 1) - tar_trial_sums)\n",
    "\n",
    "    frr = np.concatenate((np.atleast_1d(0), tar_trial_sums / target_scores.size))  # false rejection rates\n",
    "    far = np.concatenate((np.atleast_1d(1), nontarget_trial_sums / nontarget_scores.size))  # false acceptance rates\n",
    "    thresholds = np.concatenate((np.atleast_1d(all_scores[indices[0]] - 0.001), all_scores[indices]))  # Thresholds are the sorted scores\n",
    "\n",
    "    return frr, far, thresholds\n",
    "\n",
    "\n",
    "def compute_eer(target_scores, nontarget_scores):\n",
    "    \"\"\" Returns equal error rate (EER) and the corresponding threshold. \"\"\"\n",
    "    frr, far, thresholds = compute_det_curve(target_scores, nontarget_scores)\n",
    "    abs_diffs = np.abs(frr - far)\n",
    "    min_index = np.argmin(abs_diffs)\n",
    "    eer = np.mean((frr[min_index], far[min_index]))\n",
    "    return eer, thresholds[min_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def compute_det_curve(target_scores, nontarget_scores):\n",
    "    n_scores = target_scores.size + nontarget_scores.size\n",
    "    all_scores = np.concatenate((target_scores, nontarget_scores))\n",
    "    labels = np.concatenate((np.ones(target_scores.size), np.zeros(nontarget_scores.size)))\n",
    "\n",
    "    # Sort labels based on scores\n",
    "    indices = np.argsort(all_scores, kind='mergesort')\n",
    "    labels = labels[indices]\n",
    "\n",
    "    # Compute false rejection and false acceptance rates\n",
    "    tar_trial_sums = np.cumsum(labels)\n",
    "    nontarget_trial_sums = nontarget_scores.size - (np.arange(1, n_scores + 1) - tar_trial_sums)\n",
    "\n",
    "    frr = np.concatenate((np.atleast_1d(0), tar_trial_sums / target_scores.size))  # false rejection rates\n",
    "    far = np.concatenate((np.atleast_1d(1), nontarget_trial_sums / nontarget_scores.size))  # false acceptance rates\n",
    "    thresholds = np.concatenate((np.atleast_1d(all_scores[indices[0]] - 0.001), all_scores[indices]))  # Thresholds are the sorted scores\n",
    "\n",
    "    return frr, far, thresholds\n",
    "\n",
    "def compute_eer(target_scores, nontarget_scores):\n",
    "    \"\"\" Returns equal error rate (EER) and the corresponding threshold. \"\"\"\n",
    "    frr, far, thresholds = compute_det_curve(target_scores, nontarget_scores)\n",
    "    abs_diffs = np.abs(frr - far)\n",
    "    min_index = np.argmin(abs_diffs)\n",
    "    eer = np.mean((frr[min_index], far[min_index]))\n",
    "    return eer, thresholds[min_index]\n",
    "\n",
    "def train_model(model, train_loader, test_loader, epochs, device):\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(params=model.parameters())\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    for i in tqdm(range(epochs)):\n",
    "        train_preds = torch.tensor([], device=device)\n",
    "        val_preds = torch.tensor([], device=device)\n",
    "        train_actual = torch.tensor([], device=device)\n",
    "        val_actual = torch.tensor([], device=device)\n",
    "        \n",
    "        print(\"\\nTraining:\")\n",
    "        model.train()\n",
    "        \n",
    "        temp_train_loss = []\n",
    "        temp_val_loss = []\n",
    "    \n",
    "        net_train_loss = 0\n",
    "        net_val_loss = 0\n",
    "        \n",
    "        with tqdm(total=len(train_loader)) as pbar:\n",
    "            for x, y, _ in train_loader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device).type(torch.float32)\n",
    "\n",
    "                logits = model(x)\n",
    "        \n",
    "                optimizer.zero_grad()\n",
    "                loss = loss_fn(logits.squeeze(), y)\n",
    "                \n",
    "                preds = torch.sigmoid(logits).detach().squeeze()\n",
    "                train_preds = torch.cat((train_preds, preds))\n",
    "                train_actual = torch.cat((train_actual, y))\n",
    "                \n",
    "                temp_train_loss.append(loss.item())\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                pbar.update(1)\n",
    "            pbar.close()\n",
    "        \n",
    "        net_train_loss = sum(temp_train_loss) / len(temp_train_loss)\n",
    "    \n",
    "        print(\"Testing:\")\n",
    "        model.eval()\n",
    "    \n",
    "        with tqdm(total=len(test_loader)) as pbar2:\n",
    "            for x, y, _ in test_loader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device).type(torch.float32)\n",
    "                \n",
    "                with torch.inference_mode():\n",
    "                    logits = model(x)\n",
    "                    loss = loss_fn(logits.squeeze(), y.type(torch.float32))\n",
    "                    \n",
    "                    preds = torch.sigmoid(logits).detach().squeeze()\n",
    "                    val_preds = torch.cat((val_preds, preds))\n",
    "                    val_actual = torch.cat((val_actual, y))\n",
    "                    \n",
    "                    temp_val_loss.append(loss.item())\n",
    "    \n",
    "                    pbar2.update(1)\n",
    "            pbar2.close()\n",
    "    \n",
    "        net_val_loss = sum(temp_val_loss) / len(temp_val_loss)\n",
    "        \n",
    "        # Compute EER for training and validation sets\n",
    "        train_preds_np = train_preds.cpu().numpy()\n",
    "        train_actual_np = train_actual.cpu().numpy()\n",
    "        val_preds_np = val_preds.cpu().numpy()\n",
    "        val_actual_np = val_actual.cpu().numpy()\n",
    "        \n",
    "        \n",
    "        # Get target and nontarget scores for train set\n",
    "        train_target_scores = train_preds_np[train_actual_np == 1]\n",
    "        train_nontarget_scores = train_preds_np[train_actual_np == 0]\n",
    "        \n",
    "        # Get target and nontarget scores for val set\n",
    "        val_target_scores = val_preds_np[val_actual_np == 1]\n",
    "        val_nontarget_scores = val_preds_np[val_actual_np == 0]\n",
    "        \n",
    "        # Compute EER for training set\n",
    "        train_eer, train_eer_threshold = compute_eer(train_target_scores, train_nontarget_scores)\n",
    "        # Compute EER for validation set\n",
    "        val_eer, val_eer_threshold = compute_eer(val_target_scores, val_nontarget_scores)\n",
    "        \n",
    "        print(f\"Epoch {i + 1}/{epochs}\")\n",
    "        print(f\"Train Loss: {net_train_loss:.4f}\")\n",
    "        print(f\"Val Loss: {net_val_loss:.4f}\")\n",
    "        print(f\"Train EER: {train_eer:.4f} at threshold {train_eer_threshold:.4f}\")\n",
    "        print(f\"Val EER: {val_eer:.4f} at threshold {val_eer_threshold:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
