{
 "cells": [
  {
   "cell_type": "raw",
   "id": "ebc866f1-6bcb-459e-a024-e0d78d069489",
   "metadata": {},
   "source": [
    "! pip install torch\n",
    "! pip install librosa\n",
    "! pip install torchaudio\n",
    "! pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef97b4e-79f5-4346-8c2c-a05a4f6ced2d",
   "metadata": {},
   "source": [
    "## HYPERPARAMETERS/ARGUMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a866f527-ae74-4a87-9ccd-ff084d3c2599",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=8\n",
    "NUM_WORKERS=4\n",
    "PATH='./temp/ds/'\n",
    "FRONTEND='rawnet' # \"rawnet\", \"spectrogram\", \"mel-spectrogram\", \"lfcc\", \"mfcc\", \"hubert\", \"mms\", \"xlsr\", \"mrhubert\", \"wavlablm\"\n",
    "LOAD_FROM=None\n",
    "LOG_DIR='./logs'\n",
    "RESUME_TRAIN=False\n",
    "EPOCHS=100\n",
    "DEBUG=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cb163b-d432-444b-837b-5d66bb3954f0",
   "metadata": {},
   "source": [
    "### Importing all libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40b22e6f-56da-4f19-bbbf-39416f9196f5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os, sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import datetime, random\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset\n",
    "import librosa\n",
    "#from models.model import SVDDModel\n",
    "#from utils import seed_worker, set_seed, compute_eer\n",
    "\n",
    "import torchaudio\n",
    "from torch import Tensor\n",
    "from typing import Union\n",
    "\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(f\"Using: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e751f96-b397-4a8b-8382-11d2e87f55b0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def pad_random(x: np.ndarray, max_len: int = 64000):\n",
    "    x_len = x.shape[0]\n",
    "    if x_len > max_len:\n",
    "        stt = np.random.randint(x_len - max_len)\n",
    "        return x[stt:stt + max_len]\n",
    "\n",
    "    num_repeats = int(max_len / x_len) + 1\n",
    "    padded_x = np.tile(x, (num_repeats))\n",
    "    return pad_random(padded_x, max_len)\n",
    "\n",
    "class SVDD2024(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for the SVDD 2024 dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_dir, partition=\"train\", max_len=64000):\n",
    "        assert partition in [\"train\", \"dev\", \"test\"], \"Invalid partition. Must be one of ['train', 'dev', 'test']\"\n",
    "        self.base_dir = base_dir\n",
    "        self.partition = partition\n",
    "        self.base_dir = os.path.join(base_dir, partition + \"_set\")\n",
    "        self.max_len = max_len\n",
    "        try:\n",
    "            with open(os.path.join(base_dir, f\"{partition}.txt\"), \"r\") as f:\n",
    "                self.file_list = f.readlines()\n",
    "        except FileNotFoundError:\n",
    "            if partition == \"test\":\n",
    "                self.file_list = []\n",
    "                # get all *.flac files in the test_set directory\n",
    "                for root, _, files in os.walk(self.base_dir):\n",
    "                    for file in files:\n",
    "                        if file.endswith(\".flac\"):\n",
    "                            self.file_list.append(file)\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"File {partition}.txt not found in {base_dir}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, index):            \n",
    "        if self.partition == \"test\":\n",
    "            file_name = self.file_list[index].strip()\n",
    "            label = 0 # dummy label. Not used for test set.\n",
    "        else:\n",
    "            file = self.file_list[index]\n",
    "            file_name = file.split(\" \")[2].strip()\n",
    "            bonafide_or_spoof = file.split(\" \")[-1].strip()\n",
    "            label = 1 if bonafide_or_spoof == \"bonafide\" else 0\n",
    "        try:\n",
    "            x, _ = librosa.load(os.path.join(self.base_dir, file_name + \".flac\"), sr=16000, mono=True)\n",
    "            x = pad_random(x, self.max_len)\n",
    "            x = librosa.util.normalize(x)\n",
    "            # file_name is used for generating the score file for submission\n",
    "            return x, label, file_name\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_name}: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b80f512-4c9d-4bbf-a3a3-45f4e078b252",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def seed_worker(worker_id):\n",
    "    \"\"\"\n",
    "    Used in generating seed for the worker of torch.utils.data.Dataloader\n",
    "    \"\"\"\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\" \n",
    "    set initial seed for reproduction\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def compute_det_curve(target_scores, nontarget_scores):\n",
    "    n_scores = target_scores.size + nontarget_scores.size\n",
    "    all_scores = np.concatenate((target_scores, nontarget_scores))\n",
    "    labels = np.concatenate((np.ones(target_scores.size), np.zeros(nontarget_scores.size)))\n",
    "\n",
    "    # Sort labels based on scores\n",
    "    indices = np.argsort(all_scores, kind='mergesort')\n",
    "    labels = labels[indices]\n",
    "\n",
    "    # Compute false rejection and false acceptance rates\n",
    "    tar_trial_sums = np.cumsum(labels)\n",
    "    nontarget_trial_sums = nontarget_scores.size - (np.arange(1, n_scores + 1) - tar_trial_sums)\n",
    "\n",
    "    frr = np.concatenate((np.atleast_1d(0), tar_trial_sums / target_scores.size))  # false rejection rates\n",
    "    far = np.concatenate((np.atleast_1d(1), nontarget_trial_sums / nontarget_scores.size))  # false acceptance rates\n",
    "    thresholds = np.concatenate((np.atleast_1d(all_scores[indices[0]] - 0.001), all_scores[indices]))  # Thresholds are the sorted scores\n",
    "\n",
    "    return frr, far, thresholds\n",
    "\n",
    "def compute_eer(target_scores, nontarget_scores):\n",
    "    target_scores = np.array(target_scores).flatten()\n",
    "    nontarget_scores = np.array(nontarget_scores).flatten()\n",
    "    frr, far, thresholds = compute_det_curve(target_scores, nontarget_scores)\n",
    "    abs_diffs = np.abs(frr - far)\n",
    "    min_index = np.argmin(abs_diffs)\n",
    "    eer = np.mean((frr[min_index], far[min_index]))\n",
    "    return eer, thresholds[min_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0b7d336-33f9-43b7-a4fe-1578c262ac26",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class GraphAttentionLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        # attention map\n",
    "        self.att_proj = nn.Linear(in_dim, out_dim)\n",
    "        self.att_weight = self._init_new_params(out_dim, 1)\n",
    "\n",
    "        # project\n",
    "        self.proj_with_att = nn.Linear(in_dim, out_dim)\n",
    "        self.proj_without_att = nn.Linear(in_dim, out_dim)\n",
    "\n",
    "        # batch norm\n",
    "        self.bn = nn.BatchNorm1d(out_dim)\n",
    "\n",
    "        # dropout for inputs\n",
    "        self.input_drop = nn.Dropout(p=0.2)\n",
    "\n",
    "        # activate\n",
    "        self.act = nn.SELU(inplace=True)\n",
    "\n",
    "        # temperature\n",
    "        self.temp = 1.0\n",
    "        if \"temperature\" in kwargs:\n",
    "            self.temp = kwargs[\"temperature\"]\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x   :(#bs, #node, #dim)\n",
    "        \"\"\"\n",
    "        # apply input dropout\n",
    "        x = self.input_drop(x)\n",
    "\n",
    "        # derive attention map\n",
    "        att_map = self._derive_att_map(x)\n",
    "\n",
    "        # projection\n",
    "        x = self._project(x, att_map)\n",
    "\n",
    "        # apply batch norm\n",
    "        x = self._apply_BN(x)\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "\n",
    "    def _pairwise_mul_nodes(self, x):\n",
    "        \"\"\"\n",
    "        Calculates pairwise multiplication of nodes.\n",
    "        - for attention map\n",
    "        x           :(#bs, #node, #dim)\n",
    "        out_shape   :(#bs, #node, #node, #dim)\n",
    "        \"\"\"\n",
    "\n",
    "        nb_nodes = x.size(1)\n",
    "        x = x.unsqueeze(2).expand(-1, -1, nb_nodes, -1)\n",
    "        x_mirror = x.transpose(1, 2)\n",
    "\n",
    "        return x * x_mirror\n",
    "\n",
    "    def _derive_att_map(self, x):\n",
    "        \"\"\"\n",
    "        x           :(#bs, #node, #dim)\n",
    "        out_shape   :(#bs, #node, #node, 1)\n",
    "        \"\"\"\n",
    "        att_map = self._pairwise_mul_nodes(x)\n",
    "        # size: (#bs, #node, #node, #dim_out)\n",
    "        att_map = torch.tanh(self.att_proj(att_map))\n",
    "        # size: (#bs, #node, #node, 1)\n",
    "        att_map = torch.matmul(att_map, self.att_weight)\n",
    "\n",
    "        # apply temperature\n",
    "        att_map = att_map / self.temp\n",
    "\n",
    "        att_map = F.softmax(att_map, dim=-2)\n",
    "\n",
    "        return att_map\n",
    "\n",
    "    def _project(self, x, att_map):\n",
    "        x1 = self.proj_with_att(torch.matmul(att_map.squeeze(-1), x))\n",
    "        x2 = self.proj_without_att(x)\n",
    "\n",
    "        return x1 + x2\n",
    "\n",
    "    def _apply_BN(self, x):\n",
    "        org_size = x.size()\n",
    "        x = x.view(-1, org_size[-1])\n",
    "        x = self.bn(x)\n",
    "        x = x.view(org_size)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _init_new_params(self, *size):\n",
    "        out = nn.Parameter(torch.FloatTensor(*size))\n",
    "        nn.init.xavier_normal_(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class HtrgGraphAttentionLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.proj_type1 = nn.Linear(in_dim, in_dim)\n",
    "        self.proj_type2 = nn.Linear(in_dim, in_dim)\n",
    "\n",
    "        # attention map\n",
    "        self.att_proj = nn.Linear(in_dim, out_dim)\n",
    "        self.att_projM = nn.Linear(in_dim, out_dim)\n",
    "\n",
    "        self.att_weight11 = self._init_new_params(out_dim, 1)\n",
    "        self.att_weight22 = self._init_new_params(out_dim, 1)\n",
    "        self.att_weight12 = self._init_new_params(out_dim, 1)\n",
    "        self.att_weightM = self._init_new_params(out_dim, 1)\n",
    "\n",
    "        # project\n",
    "        self.proj_with_att = nn.Linear(in_dim, out_dim)\n",
    "        self.proj_without_att = nn.Linear(in_dim, out_dim)\n",
    "\n",
    "        self.proj_with_attM = nn.Linear(in_dim, out_dim)\n",
    "        self.proj_without_attM = nn.Linear(in_dim, out_dim)\n",
    "\n",
    "        # batch norm\n",
    "        self.bn = nn.BatchNorm1d(out_dim)\n",
    "\n",
    "        # dropout for inputs\n",
    "        self.input_drop = nn.Dropout(p=0.2)\n",
    "\n",
    "        # activate\n",
    "        self.act = nn.SELU(inplace=True)\n",
    "\n",
    "        # temperature\n",
    "        self.temp = 1.0\n",
    "        if \"temperature\" in kwargs:\n",
    "            self.temp = kwargs[\"temperature\"]\n",
    "\n",
    "    def forward(self, x1, x2, master=None):\n",
    "        \"\"\"\n",
    "        x1  :(#bs, #node, #dim)\n",
    "        x2  :(#bs, #node, #dim)\n",
    "        \"\"\"\n",
    "        num_type1 = x1.size(1)\n",
    "        num_type2 = x2.size(1)\n",
    "\n",
    "        x1 = self.proj_type1(x1)\n",
    "        x2 = self.proj_type2(x2)\n",
    "\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "\n",
    "        if master is None:\n",
    "            master = torch.mean(x, dim=1, keepdim=True)\n",
    "\n",
    "        # apply input dropout\n",
    "        x = self.input_drop(x)\n",
    "\n",
    "        # derive attention map\n",
    "        att_map = self._derive_att_map(x, num_type1, num_type2)\n",
    "\n",
    "        # directional edge for master node\n",
    "        master = self._update_master(x, master)\n",
    "\n",
    "        # projection\n",
    "        x = self._project(x, att_map)\n",
    "\n",
    "        # apply batch norm\n",
    "        x = self._apply_BN(x)\n",
    "        x = self.act(x)\n",
    "\n",
    "        x1 = x.narrow(1, 0, num_type1)\n",
    "        x2 = x.narrow(1, num_type1, num_type2)\n",
    "\n",
    "        return x1, x2, master\n",
    "\n",
    "    def _update_master(self, x, master):\n",
    "\n",
    "        att_map = self._derive_att_map_master(x, master)\n",
    "        master = self._project_master(x, master, att_map)\n",
    "\n",
    "        return master\n",
    "\n",
    "    def _pairwise_mul_nodes(self, x):\n",
    "        \"\"\"\n",
    "        Calculates pairwise multiplication of nodes.\n",
    "        - for attention map\n",
    "        x           :(#bs, #node, #dim)\n",
    "        out_shape   :(#bs, #node, #node, #dim)\n",
    "        \"\"\"\n",
    "\n",
    "        nb_nodes = x.size(1)\n",
    "        x = x.unsqueeze(2).expand(-1, -1, nb_nodes, -1)\n",
    "        x_mirror = x.transpose(1, 2)\n",
    "\n",
    "        return x * x_mirror\n",
    "\n",
    "    def _derive_att_map_master(self, x, master):\n",
    "        \"\"\"\n",
    "        x           :(#bs, #node, #dim)\n",
    "        out_shape   :(#bs, #node, #node, 1)\n",
    "        \"\"\"\n",
    "        att_map = x * master\n",
    "        att_map = torch.tanh(self.att_projM(att_map))\n",
    "\n",
    "        att_map = torch.matmul(att_map, self.att_weightM)\n",
    "\n",
    "        # apply temperature\n",
    "        att_map = att_map / self.temp\n",
    "\n",
    "        att_map = F.softmax(att_map, dim=-2)\n",
    "\n",
    "        return att_map\n",
    "\n",
    "    def _derive_att_map(self, x, num_type1, num_type2):\n",
    "        \"\"\"\n",
    "        x           :(#bs, #node, #dim)\n",
    "        out_shape   :(#bs, #node, #node, 1)\n",
    "        \"\"\"\n",
    "        att_map = self._pairwise_mul_nodes(x)\n",
    "        # size: (#bs, #node, #node, #dim_out)\n",
    "        att_map = torch.tanh(self.att_proj(att_map))\n",
    "        # size: (#bs, #node, #node, 1)\n",
    "\n",
    "        att_board = torch.zeros_like(att_map[:, :, :, 0]).unsqueeze(-1)\n",
    "\n",
    "        att_board[:, :num_type1, :num_type1, :] = torch.matmul(\n",
    "            att_map[:, :num_type1, :num_type1, :], self.att_weight11\n",
    "        )\n",
    "        att_board[:, num_type1:, num_type1:, :] = torch.matmul(\n",
    "            att_map[:, num_type1:, num_type1:, :], self.att_weight22\n",
    "        )\n",
    "        att_board[:, :num_type1, num_type1:, :] = torch.matmul(\n",
    "            att_map[:, :num_type1, num_type1:, :], self.att_weight12\n",
    "        )\n",
    "        att_board[:, num_type1:, :num_type1, :] = torch.matmul(\n",
    "            att_map[:, num_type1:, :num_type1, :], self.att_weight12\n",
    "        )\n",
    "\n",
    "        att_map = att_board\n",
    "\n",
    "        # att_map = torch.matmul(att_map, self.att_weight12)\n",
    "\n",
    "        # apply temperature\n",
    "        att_map = att_map / self.temp\n",
    "\n",
    "        att_map = F.softmax(att_map, dim=-2)\n",
    "\n",
    "        return att_map\n",
    "\n",
    "    def _project(self, x, att_map):\n",
    "        x1 = self.proj_with_att(torch.matmul(att_map.squeeze(-1), x))\n",
    "        x2 = self.proj_without_att(x)\n",
    "\n",
    "        return x1 + x2\n",
    "\n",
    "    def _project_master(self, x, master, att_map):\n",
    "\n",
    "        x1 = self.proj_with_attM(torch.matmul(att_map.squeeze(-1).unsqueeze(1), x))\n",
    "        x2 = self.proj_without_attM(master)\n",
    "\n",
    "        return x1 + x2\n",
    "\n",
    "    def _apply_BN(self, x):\n",
    "        org_size = x.size()\n",
    "        x = x.view(-1, org_size[-1])\n",
    "        x = self.bn(x)\n",
    "        x = x.view(org_size)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _init_new_params(self, *size):\n",
    "        out = nn.Parameter(torch.FloatTensor(*size))\n",
    "        nn.init.xavier_normal_(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class GraphPool(nn.Module):\n",
    "    def __init__(self, k: float, in_dim: int, p: Union[float, int]):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.proj = nn.Linear(in_dim, 1)\n",
    "        self.drop = nn.Dropout(p=p) if p > 0 else nn.Identity()\n",
    "        self.in_dim = in_dim\n",
    "\n",
    "    def forward(self, h):\n",
    "        Z = self.drop(h)\n",
    "        weights = self.proj(Z)\n",
    "        scores = self.sigmoid(weights)\n",
    "        new_h = self.top_k_graph(scores, h, self.k)\n",
    "\n",
    "        return new_h\n",
    "\n",
    "    def top_k_graph(self, scores, h, k):\n",
    "        \"\"\"\n",
    "        args\n",
    "        =====\n",
    "        scores: attention-based weights (#bs, #node, 1)\n",
    "        h: graph data (#bs, #node, #dim)\n",
    "        k: ratio of remaining nodes, (float)\n",
    "\n",
    "        returns\n",
    "        =====\n",
    "        h: graph pool applied data (#bs, #node', #dim)\n",
    "        \"\"\"\n",
    "        _, n_nodes, n_feat = h.size()\n",
    "        n_nodes = max(int(n_nodes * k), 1)\n",
    "        _, idx = torch.topk(scores, n_nodes, dim=1)\n",
    "        idx = idx.expand(-1, -1, n_feat)\n",
    "\n",
    "        h = h * scores\n",
    "        h = torch.gather(h, 1, idx)\n",
    "\n",
    "        return h\n",
    "\n",
    "\n",
    "class CONV(nn.Module):\n",
    "    @staticmethod\n",
    "    def to_mel(hz):\n",
    "        return 2595 * np.log10(1 + hz / 700)\n",
    "\n",
    "    @staticmethod\n",
    "    def to_hz(mel):\n",
    "        return 700 * (10 ** (mel / 2595) - 1)\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        sample_rate=16000,\n",
    "        in_channels=1,\n",
    "        stride=1,\n",
    "        padding=0,\n",
    "        dilation=1,\n",
    "        bias=False,\n",
    "        groups=1,\n",
    "        mask=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if in_channels != 1:\n",
    "\n",
    "            msg = (\n",
    "                \"SincConv only support one input channel (here, in_channels = {%i})\"\n",
    "                % (in_channels)\n",
    "            )\n",
    "            raise ValueError(msg)\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sample_rate = sample_rate\n",
    "\n",
    "        # Forcing the filters to be odd (i.e, perfectly symmetrics)\n",
    "        if kernel_size % 2 == 0:\n",
    "            self.kernel_size = self.kernel_size + 1\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.mask = mask\n",
    "        if bias:\n",
    "            raise ValueError(\"SincConv does not support bias.\")\n",
    "        if groups > 1:\n",
    "            raise ValueError(\"SincConv does not support groups.\")\n",
    "\n",
    "        NFFT = 512\n",
    "        f = int(self.sample_rate / 2) * np.linspace(0, 1, int(NFFT / 2) + 1)\n",
    "        fmel = self.to_mel(f)\n",
    "        fmelmax = np.max(fmel)\n",
    "        fmelmin = np.min(fmel)\n",
    "        filbandwidthsmel = np.linspace(fmelmin, fmelmax, self.out_channels + 1)\n",
    "        filbandwidthsf = self.to_hz(filbandwidthsmel)\n",
    "\n",
    "        self.mel = filbandwidthsf\n",
    "        self.hsupp = torch.arange(\n",
    "            -(self.kernel_size - 1) / 2, (self.kernel_size - 1) / 2 + 1\n",
    "        )\n",
    "        self.band_pass = torch.zeros(self.out_channels, self.kernel_size)\n",
    "        for i in range(len(self.mel) - 1):\n",
    "            fmin = self.mel[i]\n",
    "            fmax = self.mel[i + 1]\n",
    "            hHigh = (2 * fmax / self.sample_rate) * np.sinc(\n",
    "                2 * fmax * self.hsupp / self.sample_rate\n",
    "            )\n",
    "            hLow = (2 * fmin / self.sample_rate) * np.sinc(\n",
    "                2 * fmin * self.hsupp / self.sample_rate\n",
    "            )\n",
    "            hideal = hHigh - hLow\n",
    "\n",
    "            self.band_pass[i, :] = Tensor(np.hamming(self.kernel_size)) * Tensor(hideal)\n",
    "\n",
    "    def forward(self, x, mask=False):\n",
    "        band_pass_filter = self.band_pass.clone().to(x.device)\n",
    "        if mask:\n",
    "            A = np.random.uniform(0, 20)\n",
    "            A = int(A)\n",
    "            A0 = random.randint(0, band_pass_filter.shape[0] - A)\n",
    "            band_pass_filter[A0 : A0 + A, :] = 0\n",
    "        else:\n",
    "            band_pass_filter = band_pass_filter\n",
    "\n",
    "        self.filters = (band_pass_filter).view(self.out_channels, 1, self.kernel_size)\n",
    "\n",
    "        return F.conv1d(\n",
    "            x,\n",
    "            self.filters,\n",
    "            stride=self.stride,\n",
    "            padding=self.padding,\n",
    "            dilation=self.dilation,\n",
    "            bias=None,\n",
    "            groups=1,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "class AASIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        d_args = {\n",
    "            \"nb_samp\": 64600,\n",
    "            \"first_conv\": 128,\n",
    "            \"filts\": [70, [1, 32], [32, 32], [32, 64], [64, 64]],\n",
    "            \"gat_dims\": [64, 32],\n",
    "            \"pool_ratios\": [0.5, 0.7, 0.5, 0.5],\n",
    "            \"temperatures\": [2.0, 2.0, 100.0, 100.0],\n",
    "        }\n",
    "        \n",
    "        self.d_args = d_args\n",
    "        \n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=(1,1)),\n",
    "            nn.SELU(inplace=True),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, 64, kernel_size=(1,1)),\n",
    "        )\n",
    "\n",
    "        filts = d_args[\"filts\"]\n",
    "        gat_dims = d_args[\"gat_dims\"]\n",
    "        pool_ratios = d_args[\"pool_ratios\"]\n",
    "        temperatures = d_args[\"temperatures\"]\n",
    "\n",
    "        # self.conv_time = CONV(\n",
    "        #     out_channels=filts[0], kernel_size=d_args[\"first_conv\"], in_channels=1\n",
    "        # )\n",
    "\n",
    "        self.drop = nn.Dropout(0.5, inplace=True)\n",
    "        self.drop_way = nn.Dropout(0.2, inplace=True)\n",
    "        self.selu = nn.SELU(inplace=True)\n",
    "\n",
    "        self.pos_S = nn.Parameter(torch.randn(1, 23, filts[-1][-1]))\n",
    "        self.master1 = nn.Parameter(torch.randn(1, 1, gat_dims[0]))\n",
    "        self.master2 = nn.Parameter(torch.randn(1, 1, gat_dims[0]))\n",
    "\n",
    "        self.GAT_layer_S = GraphAttentionLayer(\n",
    "            filts[-1][-1], gat_dims[0], temperature=temperatures[0]\n",
    "        )\n",
    "        self.GAT_layer_T = GraphAttentionLayer(\n",
    "            filts[-1][-1], gat_dims[0], temperature=temperatures[1]\n",
    "        )\n",
    "\n",
    "        self.HtrgGAT_layer_ST11 = HtrgGraphAttentionLayer(\n",
    "            gat_dims[0], gat_dims[1], temperature=temperatures[2]\n",
    "        )\n",
    "        self.HtrgGAT_layer_ST12 = HtrgGraphAttentionLayer(\n",
    "            gat_dims[1], gat_dims[1], temperature=temperatures[2]\n",
    "        )\n",
    "\n",
    "        self.HtrgGAT_layer_ST21 = HtrgGraphAttentionLayer(\n",
    "            gat_dims[0], gat_dims[1], temperature=temperatures[2]\n",
    "        )\n",
    "\n",
    "        self.HtrgGAT_layer_ST22 = HtrgGraphAttentionLayer(\n",
    "            gat_dims[1], gat_dims[1], temperature=temperatures[2]\n",
    "        )\n",
    "\n",
    "        self.pool_S = GraphPool(pool_ratios[0], gat_dims[0], 0.3)\n",
    "        self.pool_T = GraphPool(pool_ratios[1], gat_dims[0], 0.3)\n",
    "        self.pool_hS1 = GraphPool(pool_ratios[2], gat_dims[1], 0.3)\n",
    "        self.pool_hT1 = GraphPool(pool_ratios[2], gat_dims[1], 0.3)\n",
    "\n",
    "        self.pool_hS2 = GraphPool(pool_ratios[2], gat_dims[1], 0.3)\n",
    "        self.pool_hT2 = GraphPool(pool_ratios[2], gat_dims[1], 0.3)\n",
    "\n",
    "        self.out_layer = nn.Linear(5 * gat_dims[1], 1)\n",
    "\n",
    "    def forward(self, x, Freq_aug=False):\n",
    "        x = self.attention(x)\n",
    "        # spectral GAT (GAT-S)\n",
    "        # e_S, _ = torch.max(torch.abs(x), dim=3)  # max along time\n",
    "        w1 = F.softmax(x, dim=-1)\n",
    "        m1 = torch.sum(x * w1, dim=-1)\n",
    "        e_S = m1.transpose(1, 2) + self.pos_S\n",
    "\n",
    "        gat_S = self.GAT_layer_S(e_S)\n",
    "        out_S = self.pool_S(gat_S)  # (#bs, #node, #dim)\n",
    "\n",
    "        # temporal GAT (GAT-T)\n",
    "        w2 = F.softmax(x, dim=-2)\n",
    "        m2 = torch.sum(x * w2, dim=-2)\n",
    "        e_T = m2.transpose(1, 2)\n",
    "\n",
    "        gat_T = self.GAT_layer_T(e_T)\n",
    "        out_T = self.pool_T(gat_T)\n",
    "\n",
    "        # learnable master node\n",
    "        master1 = self.master1.expand(x.size(0), -1, -1)\n",
    "        master2 = self.master2.expand(x.size(0), -1, -1)\n",
    "\n",
    "        # inference 1\n",
    "        out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(\n",
    "            out_T, out_S, master=self.master1\n",
    "        )\n",
    "\n",
    "        out_S1 = self.pool_hS1(out_S1)\n",
    "        out_T1 = self.pool_hT1(out_T1)\n",
    "\n",
    "        out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(\n",
    "            out_T1, out_S1, master=master1\n",
    "        )\n",
    "        out_T1 = out_T1 + out_T_aug\n",
    "        out_S1 = out_S1 + out_S_aug\n",
    "        master1 = master1 + master_aug\n",
    "\n",
    "        # inference 2\n",
    "        out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(\n",
    "            out_T, out_S, master=self.master2\n",
    "        )\n",
    "        out_S2 = self.pool_hS2(out_S2)\n",
    "        out_T2 = self.pool_hT2(out_T2)\n",
    "\n",
    "        out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(\n",
    "            out_T2, out_S2, master=master2\n",
    "        )\n",
    "        out_T2 = out_T2 + out_T_aug\n",
    "        out_S2 = out_S2 + out_S_aug\n",
    "        master2 = master2 + master_aug\n",
    "\n",
    "        out_T1 = self.drop_way(out_T1)\n",
    "        out_T2 = self.drop_way(out_T2)\n",
    "        out_S1 = self.drop_way(out_S1)\n",
    "        out_S2 = self.drop_way(out_S2)\n",
    "        master1 = self.drop_way(master1)\n",
    "        master2 = self.drop_way(master2)\n",
    "\n",
    "        out_T = torch.max(out_T1, out_T2)\n",
    "        out_S = torch.max(out_S1, out_S2)\n",
    "        master = torch.max(master1, master2)\n",
    "\n",
    "        T_max, _ = torch.max(torch.abs(out_T), dim=1)\n",
    "        T_avg = torch.mean(out_T, dim=1)\n",
    "\n",
    "        S_max, _ = torch.max(torch.abs(out_S), dim=1)\n",
    "        S_avg = torch.mean(out_S, dim=1)\n",
    "\n",
    "        last_hidden = torch.cat([T_max, T_avg, S_max, S_avg, master.squeeze(1)], dim=1)\n",
    "\n",
    "        last_hidden = self.drop(last_hidden)\n",
    "        output = self.out_layer(last_hidden)\n",
    "\n",
    "        return last_hidden, output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Residual_block(nn.Module):\n",
    "    def __init__(self, nb_filts, first=False):\n",
    "        super().__init__()\n",
    "        self.first = first\n",
    "\n",
    "        if not self.first:\n",
    "            self.bn1 = nn.BatchNorm2d(num_features=nb_filts[0])\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=nb_filts[0],\n",
    "            out_channels=nb_filts[1],\n",
    "            kernel_size=(2, 3),\n",
    "            padding=(1, 1),\n",
    "            stride=1,\n",
    "        )\n",
    "        self.selu = nn.SELU(inplace=True)\n",
    "\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=nb_filts[1])\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=nb_filts[1],\n",
    "            out_channels=nb_filts[1],\n",
    "            kernel_size=(2, 3),\n",
    "            padding=(0, 1),\n",
    "            stride=1,\n",
    "        )\n",
    "\n",
    "        if nb_filts[0] != nb_filts[1]:\n",
    "            self.downsample = True\n",
    "            self.conv_downsample = nn.Conv2d(\n",
    "                in_channels=nb_filts[0],\n",
    "                out_channels=nb_filts[1],\n",
    "                padding=(0, 1),\n",
    "                kernel_size=(1, 3),\n",
    "                stride=1,\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            self.downsample = False\n",
    "        self.mp = nn.MaxPool2d((1, 3))  # self.mp = nn.MaxPool2d((1,4))\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if not self.first:\n",
    "            out = self.bn1(x)\n",
    "            out = self.selu(out)\n",
    "        else:\n",
    "            out = x\n",
    "        out = self.conv1(x)\n",
    "\n",
    "        # print('out',out.shape)\n",
    "        out = self.bn2(out)\n",
    "        out = self.selu(out)\n",
    "        # print('out',out.shape)\n",
    "        out = self.conv2(out)\n",
    "        # print('conv2 out',out.shape)\n",
    "        if self.downsample:\n",
    "            identity = self.conv_downsample(identity)\n",
    "\n",
    "        out += identity\n",
    "        out = self.mp(out)\n",
    "        return out\n",
    "\n",
    "class SincConv(nn.Module):\n",
    "    @staticmethod\n",
    "    def to_mel(hz):\n",
    "        return 2595 * np.log10(1 + hz / 700)\n",
    "\n",
    "    @staticmethod\n",
    "    def to_hz(mel):\n",
    "        return 700 * (10 ** (mel / 2595) - 1)\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        sample_rate=16000,\n",
    "        in_channels=1,\n",
    "        stride=1,\n",
    "        padding=0,\n",
    "        dilation=1,\n",
    "        bias=False,\n",
    "        groups=1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        filts = [70, [1, 32], [32, 32], [32, 64], [64, 64]]\n",
    "        \n",
    "        if in_channels != 1:\n",
    "\n",
    "            msg = (\n",
    "                \"SincConv only support one input channel (here, in_channels = {%i})\"\n",
    "                % (in_channels)\n",
    "            )\n",
    "            raise ValueError(msg)\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sample_rate = sample_rate\n",
    "\n",
    "        # Forcing the filters to be odd (i.e, perfectly symmetrics)\n",
    "        if kernel_size % 2 == 0:\n",
    "            self.kernel_size = self.kernel_size + 1\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        if bias:\n",
    "            raise ValueError(\"SincConv does not support bias.\")\n",
    "        if groups > 1:\n",
    "            raise ValueError(\"SincConv does not support groups.\")\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[1], first=True)),\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[2])),\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[3])),\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[4])),\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[4])),\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[4])),\n",
    "        )\n",
    "        \n",
    "        self.first_bn = nn.BatchNorm2d(num_features=1)\n",
    "        self.selu = nn.SELU(inplace=True)\n",
    "\n",
    "        NFFT = 512\n",
    "        f = int(self.sample_rate / 2) * np.linspace(0, 1, int(NFFT / 2) + 1)\n",
    "        fmel = self.to_mel(f)\n",
    "        fmelmax = np.max(fmel)\n",
    "        fmelmin = np.min(fmel)\n",
    "        filbandwidthsmel = np.linspace(fmelmin, fmelmax, self.out_channels + 1)\n",
    "        filbandwidthsf = self.to_hz(filbandwidthsmel)\n",
    "\n",
    "        self.mel = filbandwidthsf\n",
    "        self.hsupp = torch.arange(\n",
    "            -(self.kernel_size - 1) / 2, (self.kernel_size - 1) / 2 + 1\n",
    "        )\n",
    "        self.band_pass = torch.zeros(self.out_channels, self.kernel_size)\n",
    "        for i in range(len(self.mel) - 1):\n",
    "            fmin = self.mel[i]\n",
    "            fmax = self.mel[i + 1]\n",
    "            hHigh = (2 * fmax / self.sample_rate) * np.sinc(\n",
    "                2 * fmax * self.hsupp / self.sample_rate\n",
    "            )\n",
    "            hLow = (2 * fmin / self.sample_rate) * np.sinc(\n",
    "                2 * fmin * self.hsupp / self.sample_rate\n",
    "            )\n",
    "            hideal = hHigh - hLow\n",
    "\n",
    "            self.band_pass[i, :] = Tensor(np.hamming(self.kernel_size)) * Tensor(hideal)\n",
    "\n",
    "    def forward(self, x):\n",
    "        band_pass_filter = self.band_pass.clone().to(x.device)\n",
    "        self.filters = (band_pass_filter).view(self.out_channels, 1, self.kernel_size)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = F.conv1d(\n",
    "            x,\n",
    "            self.filters,\n",
    "            stride=self.stride,\n",
    "            padding=self.padding,\n",
    "            dilation=self.dilation,\n",
    "            bias=None,\n",
    "            groups=1,\n",
    "        )\n",
    "        x = x.unsqueeze(dim=1)\n",
    "        x = F.max_pool2d(torch.abs(x), (3, 3))\n",
    "        x = self.first_bn(x)\n",
    "        x = self.selu(x)\n",
    "        # get embeddings using encoder\n",
    "        # (#bs, #filt, #spec, #seq)\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "\n",
    "class Spectrogram(nn.Module):\n",
    "    def __init__(self, device, sample_rate=16000, n_fft=512, win_length=512, hop_length=160, power=2, normalized=True):\n",
    "        super(Spectrogram, self).__init__()\n",
    "        self.sample_rate = sample_rate\n",
    "        self.n_fft = n_fft\n",
    "        self.win_length = win_length\n",
    "        self.hop_length = hop_length\n",
    "        self.power = power\n",
    "        self.normalized = normalized\n",
    "        \n",
    "        filts = [70, [1, 32], [32, 32], [32, 64], [64, 64]]\n",
    "        \n",
    "        self.spec = torchaudio.transforms.Spectrogram(\n",
    "            n_fft=self.n_fft,\n",
    "            win_length=self.win_length,\n",
    "            hop_length=self.hop_length,\n",
    "            power=self.power,\n",
    "            normalized=self.normalized,\n",
    "        ).to(device)\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[1], first=True)),\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[2])),\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[3])),\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[4])),\n",
    "        )\n",
    "        \n",
    "        self.linear = nn.Linear((n_fft // 2 + 1) * 4, 23 * 29) # match the output shape of the rawnet encoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.spec(x)\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(x.size(0), x.size(1), -1)\n",
    "        x = self.linear(x)\n",
    "        x = x.view(x.size(0), x.size(1), 23, 29)\n",
    "        return x\n",
    "    \n",
    "class MelSpectrogram(nn.Module):\n",
    "    def __init__(self, device, sample_rate=16000, n_mels=80, n_fft=512, win_length=512, hop_length=160):\n",
    "        super(MelSpectrogram, self).__init__()\n",
    "        self.sample_rate = sample_rate\n",
    "        self.n_mels = n_mels\n",
    "        self.n_fft = n_fft\n",
    "        self.win_length = win_length\n",
    "        self.hop_length = hop_length\n",
    "        \n",
    "        filts = [70, [1, 32], [32, 32], [32, 64], [64, 64]]\n",
    "        \n",
    "        self.melspec = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=self.sample_rate,\n",
    "            n_mels=self.n_mels,\n",
    "            n_fft=self.n_fft,\n",
    "            win_length=self.win_length,\n",
    "            hop_length=self.hop_length,\n",
    "        ).to(device)\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[1], first=True)),\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[2])),\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[3])),\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[4])),\n",
    "        )\n",
    "        \n",
    "        self.linear = nn.Linear(n_mels * 4, 23 * 29) # match the output shape of the rawnet encoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.melspec(x)\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(x.size(0), x.size(1), -1)\n",
    "        x = self.linear(x)\n",
    "        x = x.view(x.size(0), x.size(1), 23, 29)\n",
    "        return x\n",
    "    \n",
    "class LFCC(nn.Module):\n",
    "    def __init__(self, device, sample_rate=16000, n_filter=20, f_min=0.0, f_max=None, n_lfcc=60, dct_type=2, norm=\"ortho\", log_lf=False, speckwargs={\"n_fft\": 512, \"win_length\": 512, \"hop_length\": 160, \"center\": False}):\n",
    "        super(LFCC, self).__init__()\n",
    "        self.sample_rate = sample_rate\n",
    "        self.n_filter = n_filter\n",
    "        self.f_min = f_min\n",
    "        self.f_max = f_max\n",
    "        self.n_lfcc = n_lfcc\n",
    "        self.dct_type = dct_type\n",
    "        self.norm = norm\n",
    "        self.log_lf = log_lf\n",
    "        self.speckwargs = speckwargs\n",
    "        \n",
    "        filts = [70, [1, 32], [32, 32], [32, 64], [64, 64]]\n",
    "        \n",
    "        self.lfcc = torchaudio.transforms.LFCC(\n",
    "            sample_rate=self.sample_rate,\n",
    "            n_filter=self.n_filter,\n",
    "            f_min=self.f_min,\n",
    "            f_max=self.f_max,\n",
    "            n_lfcc=self.n_lfcc,\n",
    "            dct_type=self.dct_type,\n",
    "            norm=self.norm,\n",
    "            log_lf=self.log_lf,\n",
    "            speckwargs=self.speckwargs,\n",
    "        ).to(device)\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[1], first=True)),\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[2])),\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[3])),\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[4])),\n",
    "        )\n",
    "        \n",
    "        self.linear = nn.Linear(n_lfcc * 4, 23 * 29) # match the output shape of the rawnet encoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.lfcc(x)\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(x.size(0), x.size(1), -1)\n",
    "        x = self.linear(x)\n",
    "        x = x.view(x.size(0), x.size(1), 23, 29)\n",
    "        return x\n",
    "    \n",
    "class MFCC(nn.Module):\n",
    "    def __init__(self, device, sample_rate=16000, n_mfcc=40, melkwargs={\"n_fft\": 512, \"win_length\": 512, \"hop_length\": 160, \"center\": False}):\n",
    "        super(MFCC, self).__init__()\n",
    "        self.device = device\n",
    "        self.sample_rate = sample_rate\n",
    "        self.n_mfcc = n_mfcc\n",
    "        self.melkwargs = melkwargs\n",
    "        \n",
    "        filts = [70, [1, 32], [32, 32], [32, 64], [64, 64]]\n",
    "        \n",
    "        self.mfcc = torchaudio.transforms.MFCC(\n",
    "            sample_rate=self.sample_rate,\n",
    "            n_mfcc=self.n_mfcc,\n",
    "            melkwargs=self.melkwargs,\n",
    "        ).to(device)\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[1], first=True)),\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[2])),\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[3])),\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[4])),\n",
    "        )\n",
    "        \n",
    "        self.linear = nn.Linear(n_mfcc * 4, 23 * 29) # match the output shape of the rawnet encoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.mfcc(x)\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(x.size(0), x.size(1), -1)\n",
    "        x = self.linear(x)\n",
    "        x = x.view(x.size(0), x.size(1), 23, 29)\n",
    "        return x\n",
    "    \n",
    "class SSLFrontend(nn.Module):\n",
    "    def __init__(self, device, model_label, model_dim):\n",
    "        super(SSLFrontend, self).__init__()\n",
    "        if model_label == \"xlsr\":\n",
    "            task_arg = argparse.Namespace(task='audio_pretraining')\n",
    "            task = fairseq.tasks.setup_task(task_arg)\n",
    "            # https://dl.fbaipublicfiles.com/fairseq/wav2vec/xlsr2_300m.pt\n",
    "            model, _, _ = fairseq.checkpoint_utils.load_model_ensemble_and_task(['/root/xlsr2_300m.pt'], task=task)\n",
    "            self.model = model[0]\n",
    "        self.device = device\n",
    "        filts = [70, [1, 32], [32, 32], [32, 64], [64, 64]]\n",
    "\n",
    "        self.sample_rate = 16000 # only 16000 setting is supported\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[1], first=True)),\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[2])),\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[3])),\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[4])),\n",
    "        )\n",
    "        self.linear = nn.Linear(model_dim * 2, 23 * 29)\n",
    "        \n",
    "    def extract_feature(self, x):\n",
    "        if next(self.model.parameters()).device != x.device \\\n",
    "            or next(self.model.parameters()).dtype != x.dtype:\n",
    "            self.model.to(x.device, dtype=x.dtype)\n",
    "            self.model.train()\n",
    "        emb = self.model(x, mask=False, features_only=True)['x']\n",
    "        return emb\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.extract_feature(x)\n",
    "        x = x.transpose(1, 2).unsqueeze(1) # [batch, 1, seq, dim]\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(x.size(0), x.size(1), -1)\n",
    "        x = self.linear(x)\n",
    "        x = x.view(x.size(0), x.size(1), 23, 29)\n",
    "        return x\n",
    "\n",
    "\n",
    "class S3PRL(nn.Module):\n",
    "    def __init__(self, device, model_label, model_dim):\n",
    "        super(S3PRL, self).__init__()\n",
    "        if S3PRLUpstream is None:\n",
    "            raise ModuleNotFoundError(\"s3prl is not found, likely not installed, please install use `pip`\")\n",
    "\n",
    "        filts = [70, [1, 32], [32, 32], [32, 64], [64, 64]]\n",
    "\n",
    "        self.sample_rate = 16000 # only 16000 setting is supported\n",
    "        if model_label == \"mms\":\n",
    "            self.model = S3PRLUpstream(\n",
    "                \"hf_wav2vec2_custom\",\n",
    "                path_or_url=\"facebook/mms-300m\",\n",
    "            ).to(device)\n",
    "            print(\"Model has been sent to\", device)\n",
    "        else:\n",
    "            self.model = S3PRLUpstream(model_label).to(device)\n",
    "            print(\"Model has been sent to\", device)\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[1], first=True)),\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[2])),\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[3])),\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[4])),\n",
    "        )\n",
    "        self.linear = nn.Linear(model_dim * 2 * 64, 1) # match the output shape of the rawnet encoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.size()) # expected: torch.Size([batch, 64000])\n",
    "        x_lens = torch.LongTensor(x.size(0)).to(x.device)\n",
    "        x, _ = self.model(x, x_lens)\n",
    "        x = x[-1].transpose(1, 2).unsqueeze(1) # take the last hidden states\n",
    "        # print(x.size())\n",
    "        x = self.encoder(x)\n",
    "        # print(x.size())\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # print(x.size())\n",
    "        x = self.linear(x)\n",
    "        x = x.view(x.size(0), 1)\n",
    "        return x\n",
    "\n",
    "class SVDDModel(nn.Module):\n",
    "    def __init__(self, device, frontend=None):\n",
    "        super(SVDDModel, self).__init__()\n",
    "        assert frontend in [\"rawnet\", \"spectrogram\", \"mel-spectrogram\", \"lfcc\", \"mfcc\", \"hubert\", \"mms\", \"xlsr\", \"mrhubert\", \"wavlablm\"], \"Invalid frontend\"\n",
    "        if frontend == \"rawnet\":\n",
    "            # This follows AASIST's implementation\n",
    "            self.frontend = SincConv(out_channels=70, kernel_size=128, in_channels=1)\n",
    "        elif frontend == \"spectrogram\":\n",
    "            self.frontend = Spectrogram(\n",
    "                device=device,\n",
    "                sample_rate=16000,\n",
    "                n_fft=512,\n",
    "                win_length=512,\n",
    "                hop_length=160,\n",
    "                power=2,\n",
    "                normalized=True,\n",
    "            )\n",
    "        elif frontend == \"mel-spectrogram\":\n",
    "            self.frontend = MelSpectrogram(\n",
    "                device=device,\n",
    "                sample_rate=16000,\n",
    "                n_mels=80,\n",
    "                n_fft=512,\n",
    "                win_length=512,\n",
    "                hop_length=160,\n",
    "            )\n",
    "        elif frontend == \"lfcc\":\n",
    "            self.frontend = LFCC(\n",
    "                device=device,\n",
    "                sample_rate=16000,\n",
    "                n_filter=20,\n",
    "                f_min=0.0,\n",
    "                f_max=None,\n",
    "                n_lfcc=60,\n",
    "                dct_type=2,\n",
    "                norm=\"ortho\",\n",
    "                log_lf=False,\n",
    "                speckwargs={\n",
    "                    \"n_fft\": 512,\n",
    "                    \"win_length\": 512,\n",
    "                    \"hop_length\": 160,\n",
    "                    \"center\": False,\n",
    "                },\n",
    "            )\n",
    "        elif frontend == \"mfcc\":\n",
    "            self.frontend = MFCC(\n",
    "                device=device,\n",
    "                sample_rate=16000,\n",
    "                n_mfcc=40,\n",
    "                melkwargs={\n",
    "                    \"n_fft\": 512,\n",
    "                    \"win_length\": 512,\n",
    "                    \"hop_length\": 160,\n",
    "                    \"center\": False,\n",
    "                },\n",
    "            )\n",
    "        elif frontend == \"hubert\":\n",
    "            self.frontend = S3PRL(\n",
    "                device=device,\n",
    "                model_label=\"hubert\",\n",
    "                model_dim=768,\n",
    "            )\n",
    "        elif frontend == \"xlsr\":\n",
    "            self.frontend = SSLFrontend(\n",
    "                device=device,\n",
    "                model_label=\"xlsr\",\n",
    "                model_dim=1024,\n",
    "            )\n",
    "            print(\"after frontend\")\n",
    "        elif frontend == \"mrhubert\":\n",
    "            self.frontend = S3PRL(\n",
    "                device=device,\n",
    "                model_label=\"multires_hubert_multilingual_large600k\",\n",
    "                model_dim=1024,\n",
    "            )\n",
    "        elif frontend == \"wavlablm\":\n",
    "            self.frontend = S3PRL(\n",
    "                device=device,\n",
    "                model_label=\"wavlablm_ms_40k\",\n",
    "                model_dim=1024,\n",
    "            )\n",
    "        elif frontend == \"mms\":\n",
    "            self.frontend = S3PRL(\n",
    "                device=device,\n",
    "                model_label=\"mms\",\n",
    "                model_dim=1024,\n",
    "            )\n",
    "\n",
    "        self.backend = AASIST()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.frontend(x)\n",
    "        x = self.backend(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69bb1c5a-c9a7-489a-8fef-92e70e5f4a93",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class BinaryFocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=0.25, use_logits=True):\n",
    "        super(BinaryFocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.use_logits = use_logits\n",
    "        \n",
    "    def forward(self, logits, targets):\n",
    "        if self.use_logits:\n",
    "            bce_loss = F.binary_cross_entropy_with_logits(logits, targets, reduction='none')\n",
    "        else:\n",
    "            bce_loss = F.binary_cross_entropy(logits, targets, reduction='none')\n",
    "        pt = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1-pt)**self.gamma * bce_loss\n",
    "        return focal_loss.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc67c6fd-86c7-4e33-ae28-ab5c85e79d65",
   "metadata": {},
   "source": [
    "### Rest of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "250e167f-cc3f-4e9d-b95c-eb02669b1331",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = SVDD2024(PATH, partition=\"train\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, worker_init_fn=seed_worker)\n",
    "\n",
    "dev_dataset = SVDD2024(PATH, partition=\"dev\")\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, worker_init_fn=seed_worker)\n",
    "\n",
    "\n",
    "model = SVDDModel(device, frontend=FRONTEND).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50ca80c6-7c55-472a-ac66-fb7d53ea49b5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-9, betas=(0.9, 0.999))\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6)\n",
    "start_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd52db10-9787-4ab2-9aa2-e9e7f20dec35",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if RESUME_TRAIN:\n",
    "    model_state = torch.load(os.path.join(LOAD_FROM, \"checkpoints\", \"model_state.pt\"))\n",
    "    model.load_state_dict(model_state['model_state_dict'])\n",
    "    optimizer.load_state_dict(model_state['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(model_state['scheduler_state_dict'])\n",
    "    start_epoch = model_state['epoch']\n",
    "    log_dir = LOAD_FROM\n",
    "else:\n",
    "    # Create the directory for the logs\n",
    "    log_dir = os.path.join(LOG_DIR, FRONTEND)\n",
    "    os.makedirs(LOG_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "325e9e56-f714-4c0f-af28-14558450c91a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = os.path.join(log_dir, current_time)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Create the summary writer\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "# Create the directory for the checkpoints\n",
    "checkpoint_dir = os.path.join(log_dir, \"checkpoints\")\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "criterion = BinaryFocalLoss()\n",
    "\n",
    "best_val_eer = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c9b1c8f-9da2-4bf5-8d51-78e74b93c274",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:   0%|                           | 32/10551 [00:10<58:06,  3.02it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 18\u001b[0m     writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss/train\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, epoch \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader) \u001b[38;5;241m+\u001b[39m i)\n\u001b[1;32m     19\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     20\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLR/train\u001b[39m\u001b[38;5;124m\"\u001b[39m, scheduler\u001b[38;5;241m.\u001b[39mget_last_lr()[\u001b[38;5;241m0\u001b[39m], epoch \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader) \u001b[38;5;241m+\u001b[39m i)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, EPOCHS):\n",
    "        model.train()\n",
    "        pos_samples, neg_samples = [], []\n",
    "        for i, batch in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{EPOCHS}\")):\n",
    "            if DEBUG and i > 100:\n",
    "                break\n",
    "            x, label, filenames = batch\n",
    "            x = x.to(device)\n",
    "            label = label.to(device)\n",
    "            soft_label = label.float() * 0.9 + 0.05\n",
    "            _, pred = model(x)\n",
    "            loss = criterion(pred, soft_label.unsqueeze(1))\n",
    "            pos_samples.append(pred[label == 1].detach().cpu().numpy())\n",
    "            neg_samples.append(pred[label == 0].detach().cpu().numpy())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            writer.add_scalar(\"Loss/train\", loss.item(), epoch * len(train_loader) + i)\n",
    "        scheduler.step()\n",
    "        writer.add_scalar(\"LR/train\", scheduler.get_last_lr()[0], epoch * len(train_loader) + i)\n",
    "        writer.add_scalar(\"EER/train\", compute_eer(np.concatenate(pos_samples), np.concatenate(neg_samples))[0], epoch)\n",
    "        # save training state\n",
    "        model_state = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'loss': loss,\n",
    "        }\n",
    "        torch.save(model_state, os.path.join(checkpoint_dir, f\"model_state.pt\"))\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        pos_samples, neg_samples = [], []\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(tqdm(dev_loader, desc=f\"Validation\")):\n",
    "                if DEBUG and i > 100:\n",
    "                    break\n",
    "                x, label, filenames = batch\n",
    "                x = x.to(device)\n",
    "                label = label.to(device)\n",
    "                _, pred = model(x)\n",
    "                soft_label = label.float() * 0.9 + 0.05\n",
    "                loss = criterion(pred, soft_label.unsqueeze(1))\n",
    "                pos_samples.append(pred[label == 1].detach().cpu().numpy())\n",
    "                neg_samples.append(pred[label == 0].detach().cpu().numpy())\n",
    "                val_loss += loss.item()\n",
    "            val_loss /= len(dev_loader)\n",
    "            val_eer = compute_eer(np.concatenate(pos_samples), np.concatenate(neg_samples))[0]\n",
    "            writer.add_scalar(\"Loss/val\", val_loss, epoch)\n",
    "            writer.add_scalar(\"EER/val\", val_eer, epoch)\n",
    "            if val_eer < best_val_eer:\n",
    "                best_val_eer = val_eer\n",
    "                torch.save(model.state_dict(), os.path.join(checkpoint_dir, f\"best_model.pt\"))\n",
    "                pos_samples, neg_samples = [], []\n",
    "                with torch.no_grad():\n",
    "                    for i, batch in enumerate(tqdm(test_loader, desc=f\"Testing\")):\n",
    "                        x, label, filenames = batch\n",
    "                        x = x.to(device)\n",
    "                        label = label.to(device)\n",
    "                        _, pred = model(x)\n",
    "                        pos_samples.append(pred[label == 1].detach().cpu().numpy())\n",
    "                        neg_samples.append(pred[label == 0].detach().cpu().numpy())\n",
    "                    test_eer = compute_eer(np.concatenate(pos_samples), np.concatenate(neg_samples))[0]\n",
    "                    writer.add_scalar(\"EER/test\", test_eer, epoch)\n",
    "                    with open(os.path.join(log_dir, \"test_eer.txt\"), \"w\") as f:\n",
    "                        f.write(f\"At epoch {epoch}: {test_eer * 100:.4f}%\")\n",
    "            if epoch % 10 == 0: # Save every 10 epochs\n",
    "                torch.save(model.state_dict(), os.path.join(checkpoint_dir, f\"model_{epoch}_EER_{val_eer}.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c6824f-653e-4627-8588-cdce3e849ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
